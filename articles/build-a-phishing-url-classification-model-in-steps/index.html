<!doctype html><html lang="en"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width,initial-scale=1" /><title>Build a Phishing URL Classification Model in Steps - PulseGeek</title><meta name="description" content="Follow a practical workflow to design, train, and deploy a phishing URL classification model, with features, metrics, validation, and safe troubleshooting guidance." /><meta name="author" content="Aisha Ren Park" /><link rel="canonical" href="https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps" /><link rel="apple-touch-icon" sizes="180x180" href="https://pulsegeek.com/apple-touch-icon.png" /><link rel="icon" type="image/png" sizes="32x32" href="https://pulsegeek.com/favicon-32x32.png" /><link rel="icon" type="image/png" sizes="16x16" href="https://pulsegeek.com/favicon-16x16.png" /><link rel="manifest" href="https://pulsegeek.com/site.webmanifest" /><link rel="alternate" type="application/rss+xml" title="PulseGeek RSS feed" href="https://pulsegeek.com/rss.xml" /><link rel="alternate" type="application/atom+xml" title="PulseGeek Atom feed" href="https://pulsegeek.com/atom.xml" /><link rel="alternate" type="application/feed+json" title="PulseGeek JSON feed" href="https://pulsegeek.com/feed.json" /><meta property="og:title" content="Build a Phishing URL Classification Model in Steps" /><meta property="og:type" content="article" /><meta property="og:url" content="https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps" /><meta property="og:image" content="https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps/hero.webp" /><meta property="og:description" content="Follow a practical workflow to design, train, and deploy a phishing URL classification model, with features, metrics, validation, and safe troubleshooting guidance." /><meta property="og:site_name" content="PulseGeek" /><meta property="og:locale" content="en_US" /><meta property="article:author" content="Aisha Ren Park" /><meta property="article:publisher" content="PulseGeek" /><meta property="article:published_time" content="2025-10-15T09:19:00.0000000" /><meta property="article:modified_time" content="2025-10-12T21:58:07.3747145" /><meta property="article:section" content="Technology / Artificial Intelligence / AI in Cybersecurity" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:title" content="Build a Phishing URL Classification Model in Steps" /><meta name="twitter:description" content="Follow a practical workflow to design, train, and deploy a phishing URL classification model, with features, metrics, validation, and safe troubleshooting guidance." /><meta name="twitter:image" content="https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps/hero.webp" /><meta name="twitter:label1" content="Author" /><meta name="twitter:data1" content="Aisha Ren Park" /><script type="application/ld+json"> {"@context":"https://schema.org","@graph":[{"@type":"Article","@id":"https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps#article","headline":"Build a Phishing URL Classification Model in Steps","description":"Follow a practical workflow to design, train, and deploy a phishing URL classification model, with features, metrics, validation, and safe troubleshooting guidance.","image":"https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps/hero.webp","author":{"@type":"Person","@id":"https://pulsegeek.com/authors/aisha-ren-park#author","name":"Aisha Ren Park","url":"https://pulsegeek.com/authors/aisha-ren-park"},"publisher":{"@id":"https://pulsegeek.com#organization"},"datePublished":"2025-10-15T09:19:00-05:00","dateModified":"2025-10-12T21:58:07.3747145-05:00","mainEntityOfPage":"https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps","wordCount":"2675","inLanguage":"en-US"},{"@type":"Person","@id":"https://pulsegeek.com/authors/aisha-ren-park#author","name":"Aisha Ren Park","url":"https://pulsegeek.com/authors/aisha-ren-park"},{"@type":"Organization","@id":"https://pulsegeek.com#organization","url":"https://pulsegeek.com","name":"PulseGeek","logo":{"@type":"ImageObject","url":"https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps/hero.webp"}},{"@type":"WebSite","@id":"https://pulsegeek.com#website","url":"https://pulsegeek.com","name":"PulseGeek"},{"@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Home","item":"https://pulsegeek.com"},{"@type":"ListItem","position":2,"name":"Technology / Artificial Intelligence / AI in Cybersecurity","item":"https://pulsegeek.com/technology / artificial intelligence / ai in cybersecurity"},{"@type":"ListItem","position":3,"name":"Build a Phishing URL Classification Model in Steps","item":"https://pulsegeek.com/articles/build-a-phishing-url-classification-model-in-steps"}]}]} </script><script async src="https://www.googletagmanager.com/gtag/js?id=G-KN2EBXS37E"></script><script> window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-KN2EBXS37E'); </script><link href="https://pulsegeek.com/css/pico.green.min.css" rel="stylesheet" /><link href="https://pulsegeek.com/css/site.css" rel="stylesheet" /></head><body><header class="site-header"><div class="container container-narrow"><nav><ul><li><a href="https://pulsegeek.com/" class="brand" aria-label="PulseGeek home"><img src="https://pulsegeek.com/images/logo.png" srcset="https://pulsegeek.com/images/logo.png 1x, https://pulsegeek.com/images/logo@2x.png 2x" alt="PulseGeek" width="308" height="64" class="brand-logo" decoding="async" fetchpriority="high"></a></li></ul><ul><li><a href="https://pulsegeek.com/technology/">Technology</a></li></ul></nav></div></header><main class="container"><nav aria-label="Breadcrumb" class="breadcrumb"><ol><li class="breadcrumb-item" style="max-width: 180px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><a href="https://pulsegeek.com/technology/" title="Technology">Technology</a></li><li class="breadcrumb-item" style="max-width: 180px; white-space: nowrap; overflow: hidden; text-overflow: ellipsis;"><span>Artificial Intelligence</span></li></ol></nav><div class="share-buttons" aria-label="Share this article"><span>Share:</span><a class="share-btn x" href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fpulsegeek.com%2Farticles%2Fbuild-a-phishing-url-classification-model-in-steps&amp;text=Build%20a%20Phishing%20URL%20Classification%20Model%20in%20Steps%20-%20PulseGeek" target="_blank" rel="noopener" aria-label="Share on X / Twitter"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" width="20" height="20" aria-hidden="true" focusable="false"><path fill="currentColor" d="M357.2 48L427.8 48 273.6 224.2 455 464 313 464 201.7 318.6 74.5 464 3.8 464 168.7 275.5-5.2 48 140.4 48 240.9 180.9 357.2 48zM332.4 421.8l39.1 0-252.4-333.8-42 0 255.3 333.8z" /></svg></a><a class="share-btn fb" href="https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fpulsegeek.com%2Farticles%2Fbuild-a-phishing-url-classification-model-in-steps" target="_blank" rel="noopener" aria-label="Share on Facebook"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="20" height="20" aria-hidden="true" focusable="false"><path fill="currentColor" d="M512 256C512 114.6 397.4 0 256 0S0 114.6 0 256C0 376 82.7 476.8 194.2 504.5l0-170.3-52.8 0 0-78.2 52.8 0 0-33.7c0-87.1 39.4-127.5 125-127.5 16.2 0 44.2 3.2 55.7 6.4l0 70.8c-6-.6-16.5-1-29.6-1-42 0-58.2 15.9-58.2 57.2l0 27.8 83.6 0-14.4 78.2-69.3 0 0 175.9C413.8 494.8 512 386.9 512 256z" /></svg></a><a class="share-btn li" href="https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fpulsegeek.com%2Farticles%2Fbuild-a-phishing-url-classification-model-in-steps" target="_blank" rel="noopener" aria-label="Share on LinkedIn"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512" width="20" height="20" aria-hidden="true" focusable="false"><path fill="currentColor" d="M416 32L31.9 32C14.3 32 0 46.5 0 64.3L0 447.7C0 465.5 14.3 480 31.9 480L416 480c17.6 0 32-14.5 32-32.3l0-383.4C448 46.5 433.6 32 416 32zM135.4 416l-66.4 0 0-213.8 66.5 0 0 213.8-.1 0zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77zM384.3 416l-66.4 0 0-104c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9l0 105.8-66.4 0 0-213.8 63.7 0 0 29.2 .9 0c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9l0 117.2z" /></svg></a><a class="share-btn rd" href="https://www.reddit.com/submit?url=https%3A%2F%2Fpulsegeek.com%2Farticles%2Fbuild-a-phishing-url-classification-model-in-steps&amp;title=Build%20a%20Phishing%20URL%20Classification%20Model%20in%20Steps%20-%20PulseGeek" target="_blank" rel="noopener" aria-label="Share on Reddit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="20" height="20" aria-hidden="true" focusable="false"><path fill="currentColor" d="M0 256C0 114.6 114.6 0 256 0S512 114.6 512 256 397.4 512 256 512L37.1 512c-13.7 0-20.5-16.5-10.9-26.2L75 437C28.7 390.7 0 326.7 0 256zM349.6 153.6c23.6 0 42.7-19.1 42.7-42.7s-19.1-42.7-42.7-42.7c-20.6 0-37.8 14.6-41.8 34-34.5 3.7-61.4 33-61.4 68.4l0 .2c-37.5 1.6-71.8 12.3-99 29.1-10.1-7.8-22.8-12.5-36.5-12.5-33 0-59.8 26.8-59.8 59.8 0 24 14.1 44.6 34.4 54.1 2 69.4 77.6 125.2 170.6 125.2s168.7-55.9 170.6-125.3c20.2-9.6 34.1-30.2 34.1-54 0-33-26.8-59.8-59.8-59.8-13.7 0-26.3 4.6-36.4 12.4-27.4-17-62.1-27.7-100-29.1l0-.2c0-25.4 18.9-46.5 43.4-49.9 4.4 18.8 21.3 32.8 41.5 32.8l.1 .2zM177.1 246.9c16.7 0 29.5 17.6 28.5 39.3s-13.5 29.6-30.3 29.6-31.4-8.8-30.4-30.5 15.4-38.3 32.1-38.3l.1-.1zm190.1 38.3c1 21.7-13.7 30.5-30.4 30.5s-29.3-7.9-30.3-29.6 11.8-39.3 28.5-39.3 31.2 16.6 32.1 38.3l.1 .1zm-48.1 56.7c-10.3 24.6-34.6 41.9-63 41.9s-52.7-17.3-63-41.9c-1.2-2.9 .8-6.2 3.9-6.5 18.4-1.9 38.3-2.9 59.1-2.9s40.7 1 59.1 2.9c3.1 .3 5.1 3.6 3.9 6.5z" /></svg></a><a class="share-btn email" href="mailto:?subject=Build%20a%20Phishing%20URL%20Classification%20Model%20in%20Steps%20-%20PulseGeek&amp;body=https%3A%2F%2Fpulsegeek.com%2Farticles%2Fbuild-a-phishing-url-classification-model-in-steps" aria-label="Share via email"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512" width="20" height="20" aria-hidden="true" focusable="false"><path fill="currentColor" d="M61.4 64C27.5 64 0 91.5 0 125.4 0 126.3 0 127.1 .1 128L0 128 0 384c0 35.3 28.7 64 64 64l384 0c35.3 0 64-28.7 64-64l0-256-.1 0c0-.9 .1-1.7 .1-2.6 0-33.9-27.5-61.4-61.4-61.4L61.4 64zM464 192.3L464 384c0 8.8-7.2 16-16 16L64 400c-8.8 0-16-7.2-16-16l0-191.7 154.8 117.4c31.4 23.9 74.9 23.9 106.4 0L464 192.3zM48 125.4C48 118 54 112 61.4 112l389.2 0c7.4 0 13.4 6 13.4 13.4 0 4.2-2 8.2-5.3 10.7L280.2 271.5c-14.3 10.8-34.1 10.8-48.4 0L53.3 136.1c-3.3-2.5-5.3-6.5-5.3-10.7z" /></svg></a></div><article><header style="text-align:center; margin-bottom:2rem;"><h1>Build a Phishing URL Classification Model in Steps</h1><p><small> By <a href="https://pulsegeek.com/authors/aisha-ren-park/">Aisha Ren Park</a> &bull; Published <time datetime="2025-10-15T04:19:00-05:00" title="2025-10-15T04:19:00-05:00">October 15, 2025</time></small></p></header><p>Our goal is to build a phishing URL classification model that separates risky addresses from benign ones with measurable reliability. We assume Python, scikit-learn, and a modest GPU-free workstation, though CPU is sufficient for lexical features. To match practical constraints, we will emphasize URL parsing, compact text signals, and evaluation that catches both false positives and false negatives. Throughout, we align to email security realities like redirect chains and shortened links. For deeper context on broader <a class="glossary-term" href="https://pulsegeek.com/glossary/artificial-intelligence/" data-tooltip="Artificial intelligence is the field of building computer systems that can perform tasks that usually require human thinking, such as understanding language, recognizing patterns, and making decisions." tabindex="0">AI</a> defense, you can explore a primer on detection pipelines and real-world defense use cases using this overview of <a href="https://pulsegeek.com/articles/ai-in-cybersecurity-models-pipelines-and-defense">AI-driven models and security workflows</a> without leaving this guide’s focus.</p><section class="pg-summary-block pg-key-takeaways" role="note" aria-label="Key takeaways"><h2>Key takeaways</h2><ul><li>Start with clear task scope and threat model tied to URLs.</li><li>Prefer interpretable lexical features before complex models for baselines.</li><li>Use stratified splits and grouped sampling to avoid domain leakage.</li><li>Track precision, recall, and calibrated risk for operational use.</li><li>Harden against obfuscation with normalization and redirect-aware parsing.</li></ul></section><h2 id="plan-the-work" data-topic="Planning" data-summary="Define scope, risks, and success criteria">Plan the work</h2><p>Set a precise scope first, because URL classification behaves differently across email, web gateway, and endpoint logs. If your model will flag phishing in inbound email, prioritize indicators like punycode hostnames, suspicious top-level domains, and brand lookalikes. For a web proxy, you might weight path patterns and redirect frequency more heavily. A simple rule of thumb is to design features around the attacker’s cheapest evasions, such as subdomain stuffing or tokenized paths. The tradeoff is that narrower scope improves precision but risks missing threats outside defined channels. Write a short threat model stating target environment, typical benign domains, expected adversary behavior, and operational thresholds so evaluation aligns with how alerts will be consumed.</p><p>Define success criteria early to prevent metrics drift during iteration. For email screening, require recall above a practical threshold while bounding false positive rate to avoid disrupting business mail. For instance, you might aim for recall in a prioritized range while maintaining precision that respects analyst workload. Rather than inventing a number, decide acceptable volumes based on your team’s daily triage capacity and auto-quarantine policies. A limitation is that early metrics can feel arbitrary if you lack baseline telemetry. Mitigate this by piloting on a week of representative traffic and recording how many alerts analysts can review without queue buildup, then translate that observation into thresholds.</p><p>Choose a labeling strategy that is ethically and operationally sound because labels influence everything downstream. Combining open feeds with internal verdicts adds diversity but can encode source bias. To reduce bias, balance datasets by domain family and time period, and deduplicate by registrable domain to prevent leakage. Where uncertainty exists, stage disputed samples into a holdout bucket rather than forcing a guess. The tradeoff is reduced training volume, yet you gain evaluation integrity. Document your label provenance and any label confidence so you can later weight samples when calibrating probabilities. This foundation supports transparent communication with stakeholders who will question model trustworthiness.</p><div class="pg-section-summary" data-for="#plan-the-work" role="note" aria-label="Section summary"><h3 class="summary-title">Section highlights</h3><ul class="mini"><li>Define scope and threat behavior to shape feature priorities.</li><li>Set measurable precision and recall targets tied to workload.</li><li>Document label sources and curb leakage by domain deduplication.</li></ul></div><h2 id="prepare-environment" data-topic="Environment" data-summary="Assemble tools, data, and parsing utilities">Prepare environment</h2><p>Stabilize your toolkit before coding, because inconsistent parsing produces brittle features. Use Python 3.10 or newer, scikit-learn for baselines, and libraries that safely decompose URLs into scheme, host, path, query, and fragments. Favor <code>urllib.parse</code> for structure and add an IDNA handler to decode punycode domains. Include a tokenizer for path tokens and a small stoplist for common folder names like <code>images</code> or <code>static</code>. A practical dataset includes positive samples from verified phishing feeds and negatives from Alexa-like rankings combined with internal benign traffic. The tradeoff is that open lists can be noisy or stale. Mitigate by time-slicing data and reserving the newest slice for final validation.</p><p>Create a safe normalization pipeline that preserves signals while removing accidental identifiers. For hosts, lowercase, collapse consecutive dots, and decode punycode to Unicode safely. For paths, percent-decode once and avoid executing redirects. For queries, sort keys and truncate individual value lengths to a fixed budget to resist adversarial padding. Use a consistent representation of missing fields to avoid conflating absent and empty tokens. A known limitation is that aggressive normalization can erase subtle cues like double encoding. Keep both raw and normalized variants when uncertainty exists, and ablate later to see which version contributes more to predictive power.</p><p>Plan your splits to reflect deployment reality, because random shuffles overfit domain families. Use stratified splits by label and group by registrable domain or eTLD+1 so all URLs from the same domain family live in the same fold. This guards against inflated performance from memorizing hosts. To further mimic production drift, consider time-ordered validation where training uses older windows and testing uses newer traffic. Time splits reduce data volume per fold but reveal sensitivity to evolving lures. Record each fold’s composition and ensure no augmented duplicates cross boundaries. This discipline pays off when stakeholders challenge metrics with real incidents.</p><div class="pg-section-summary" data-for="#prepare-environment" role="note" aria-label="Section summary"><h3 class="summary-title">Section highlights</h3><ul class="mini"><li>Adopt consistent URL parsing and normalization to prevent brittle features.</li><li>Assemble balanced datasets and reserve a recent slice for testing.</li><li>Use grouped or time-based splits to avoid domain leakage artifacts.</li></ul></div><h2 id="execute-steps" data-topic="Execution" data-summary="Engineer features, train, and calibrate">Execute steps</h2><p>Start with interpretable lexical features, because simple signals often deliver strong baselines for URL phishing detection. Extract host tokens, character n-grams, path depth, digit ratios, suspicious TLD flags, brand name overlaps, and query key rarity. A compact yet effective approach is TF-IDF over hostname and path tokens combined with a few numeric indicators like length and entropy. The tradeoff is sensitivity to obfuscation and token explosion on noisy paths. Reduce risk using token limits and minimum document frequency. Before advanced models, consult a broader roadmap of <a class="glossary-term" href="https://pulsegeek.com/glossary/natural-language-processing/" data-tooltip="Natural language processing enables computers to understand, generate, and analyze human language, supporting chatbots, search, summarization, and document processing in business workflows." tabindex="0">NLP</a>-powered detection that contrasts URL, content, and attachments in this overview of <a href="https://pulsegeek.com/articles/phishing-defense-with-nlp-a-complete-build-guide">multi-signal phishing analysis</a> to situate these steps within end-to-end defense.</p><p>Choose a baseline <a class="glossary-term" href="https://pulsegeek.com/glossary/classification-model/" data-tooltip="A model that assigns inputs to discrete categories." tabindex="0">classifier</a> that balances speed and calibration. Linear models like logistic regression with L2 regularization perform well with sparse TF-IDF features and provide probabilistic outputs. Complement with character-level analyzers to handle misspellings and homoglyph tricks. Set a regularization sweep across a small grid and evaluate with stratified group folds. The limitation is that linear boundaries may miss rare obfuscation motifs. If needed, add a tree-based model like Gradient Boosting for numeric features only, while keeping text in the linear path to prevent overfitting. Maintain a shared calibration layer such as Platt scaling to harmonize scores when blending outputs.</p><p>Encode training flags clearly so experiments remain reproducible. Record tokenizer parameters like n-gram range and maximum features, normalization options such as punycode decoding, and model settings like C for logistic regression. Store seeds and fold assignments so reruns align exactly. Use a fixed threshold for alerts initially, then explore decision curves for business operating points. Provide a tuning notebook that shows how precision and recall trade off as thresholds move. The tradeoff is extra bookkeeping, yet these notes accelerate audits and incident reviews by showing which configuration produced specific verdicts. Below is a minimal, runnable baseline that assembles these components.</p><figure class="code-example" data-language="python" data-caption="Baseline TF-IDF plus logistic regression for phishing URL classification" data-filename="train_url_model.py"><pre tabindex="0"><code class="language-python">from urllib.parse import urlparse
import idna
import re
import pandas as pd
from sklearn.model_selection import GroupKFold
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.calibration import CalibratedClassifierCV
from sklearn.pipeline import FeatureUnion
from sklearn.metrics import classification_report
from sklearn.base import BaseEstimator, TransformerMixin

def norm_host(h):
    h = h.lower().strip(&quot;.&quot;)
    try:
        h = idna.decode(h.encode(&quot;ascii&quot;))
    except Exception:
        pass
    return re.sub(r&quot;\.+&quot;, &quot;.&quot;, h)

class URLText(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        return self
    def transform(self, X):
        texts = []
        for u in X:
            p = urlparse(u)
            host = norm_host(p.hostname or &quot;&quot;)
            path = p.path or &quot;&quot;
            texts.append(host + &quot; &quot; + path.replace(&quot;/&quot;, &quot; &quot;))
        return pd.Series(texts)

# Load CSV with columns: url, label, group (eTLD+1)
df = pd.read_csv(&quot;urls.csv&quot;)
X, y, g = df[&quot;url&quot;].values, df[&quot;label&quot;].values, df[&quot;group&quot;].values

tfidf = TfidfVectorizer(ngram_range=(3,5), analyzer=&quot;char&quot;, max_features=200000, min_df=2)
pipe = CalibratedClassifierCV(
    base_estimator=LogisticRegression(max_iter=200, C=1.0, n_jobs=1),
    method=&quot;sigmoid&quot;, cv=3
)

gkf = GroupKFold(n_splits=5)
preds, trues = [], []
for tr, te in gkf.split(X, y, groups=g):
    Xtr = tfidf.fit_transform(URLText().fit_transform(X[tr]))
    Xte = tfidf.transform(URLText().fit_transform(X[te]))
    pipe.fit(Xtr, y[tr])
    p = pipe.predict(Xte)
    trues.extend(y[te])
    preds.extend(p)

print(classification_report(trues, preds))</code></pre><figcaption>Baseline TF-IDF plus logistic regression for phishing URL classification</figcaption></figure><script type="application/ld+json">{ "@context": "https://schema.org", "@type": "SoftwareSourceCode", "programmingLanguage": "python", "codeSampleType": "snippet", "about": "A minimal TF-IDF and logistic regression baseline for phishing URL classification with grouped cross-validation.", "text": "from urllib.parse import urlparse\nimport idna\nimport re\nimport pandas as pd\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.metrics import classification_report\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\ndef norm_host(h):\n h = h.lower().strip(\".\")\n try:\n h = idna.decode(h.encode(\"ascii\"))\n except Exception:\n pass\n return re.sub(r\"\\.+\", \".\", h)\n\nclass URLText(BaseEstimator, TransformerMixin):\n def fit(self, X, y=None):\n return self\n def transform(self, X):\n texts = []\n for u in X:\n p = urlparse(u)\n host = norm_host(p.hostname or \"\")\n path = p.path or \"\"\n texts.append(host + \" \" + path.replace(\"/\", \" \"))\n return pd.Series(texts)\n\n# Load CSV with columns: url, label, group (eTLD+1)\ndf = pd.read_csv(\"urls.csv\")\nX, y, g = df[\"url\"].values, df[\"label\"].values, df[\"group\"].values\n\ntfidf = TfidfVectorizer(ngram_range=(3,5), analyzer=\"char\", max_features=200000, min_df=2)\npipe = CalibratedClassifierCV(\n base_estimator=LogisticRegression(max_iter=200, C=1.0, n_jobs=1),\n method=\"sigmoid\", cv=3\n)\n\ngkf = GroupKFold(n_splits=5)\npreds, trues = [], []\nfor tr, te in gkf.split(X, y, groups=g):\n Xtr = tfidf.fit_transform(URLText().fit_transform(X[tr]))\n Xte = tfidf.transform(URLText().fit_transform(X[te]))\n pipe.fit(Xtr, y[tr])\n p = pipe.predict(Xte)\n trues.extend(y[te])\n preds.extend(p)\n\nprint(classification_report(trues, preds))" }</script><table><thead><tr><th>Parameter</th><th>Typical choices</th><th>Tradeoff notes</th></tr></thead><tbody><tr><td>Char n-grams</td><td>3 to 5</td><td>Captures obfuscation patterns but increases feature count.</td></tr><tr><td>Max features</td><td>100k to 300k</td><td>Higher improves recall until memory and speed degrade.</td></tr><tr><td>Regularization C</td><td>0.5 to 2.0</td><td>Lower reduces variance but may miss rare attacks.</td></tr></tbody></table><ol><li><strong>Assemble datasets:</strong> combine verified phishing feeds with benign traffic and deduplicate by domain.</li><li><strong>Normalize URLs:</strong> decode punycode, lowercase hosts, and percent-decode paths once.</li><li><strong>Tokenize text:</strong> build character n-grams and path tokens with size limits.</li><li><strong>Train baseline:</strong> fit logistic regression with calibration using grouped folds.</li><li><strong>Pick threshold:</strong> evaluate precision-recall and set an operating point for alerts.</li></ol><div class="pg-section-summary" data-for="#execute-steps" role="note" aria-label="Section summary"><h3 class="summary-title">Section highlights</h3><ul class="mini"><li>Use interpretable lexical features and a calibrated linear baseline.</li><li>Record settings and folds to ensure reproducible experiments and audits.</li><li>Select thresholds from precision-recall curves for business operations.</li></ul></div><h2 id="validate-results" data-topic="Validation" data-summary="Measure performance and check leakage">Validate results</h2><p>Evaluate with stratified group folds to protect against domain leakage. Report precision, recall, <a class="glossary-term" href="https://pulsegeek.com/glossary/f1-score/" data-tooltip="A single measure combining precision and recall." tabindex="0">F1</a>, and especially false positive rate at the intended threshold. For email queues, also measure alert volume per thousand messages to estimate analyst workload. Use confusion matrices to show mistake patterns, such as benign marketing hosts mislabeled due to UTM noise. A limitation is that cross-validation can still overestimate performance if time drift is strong. Mitigate by holding out the newest time slice as a final test. When interpreting errors, compare with a list of AI-driven email signals like headers, URL behavior, and content semantics from this readable overview of threat signals worth tracking to contextualize decisions.</p><p>Calibrate probabilities so scores mean the same thing across batches. Techniques like Platt scaling map raw logits to calibrated probabilities using a small validation split. Check calibration curves and the Brier score to quantify reliability. In operations, well-calibrated scores enable tiered actions, such as immediate block above a high threshold and soft warnings for medium risk. The tradeoff is that calibration needs stable validation data and can drift. Refit the calibrator periodically using fresh samples without changing the underlying classifier unless you are versioning both together. Keep a simple policy document that maps score bands to actions to ensure predictable behavior during incidents.</p><p>Stress test robustness with adversarial patterns drawn from recent incidents. Try homograph substitutions, subdomain padding, long random paths, and excessive query parameters. Construct small synthetic cases that reflect realistic obfuscations rather than random noise. Measure the degradation in recall and track which features compensate for each pattern. A limitation is that overfitting to known tricks can harm generalization. Treat these tests as guardrails, not training data, and only introduce a few carefully labeled variants if coverage is clearly lacking. Share findings with stakeholders to set expectations about what the model does well and where layered controls still matter.</p><div class="pg-section-summary" data-for="#validate-results" role="note" aria-label="Section summary"><h3 class="summary-title">Section highlights</h3><ul class="mini"><li>Use grouped and time-sliced tests to reveal leakage and drift.</li><li>Calibrate scores to support consistent tiered actions in production.</li><li>Stress test obfuscations to map weaknesses and prioritize defenses.</li></ul></div><h2 id="troubleshoot-and-optimize" data-topic="Triage and tuning" data-summary="Fix errors and refine features">Troubleshoot and optimize</h2><p>Diagnose high false positives by inspecting top contributing n-grams and tokens for benign marketing URLs. Often, long tracking parameters or brand mentions trigger risk signals. Add lightweight mitigations such as whitelisting stable query keys, discounting known tracking hosts, or adding a feature for path randomness versus dictionary words. The tradeoff is risk of blinding the model to new threats if whitelists expand unchecked. Constrain exceptions with expiry dates and require supporting evidence for each rule. For a deeper understanding of how URLs relate to content, revisit the role of NLP across email analysis using this practical overview of language signals aligned with security tasks.</p><p>Address missed detections by enriching features that capture evasions. Add host entropy, ratio of digits to letters, presence of unicode confusables, and TLD risk buckets. Consider a small character-<a class="glossary-term" href="https://pulsegeek.com/glossary/convolutional-neural-network/" data-tooltip="Neural network using convolutions for pattern learning." tabindex="0">CNN</a> only if lexical baselines plateau, and keep it sandboxed to avoid heavy inference costs. Evaluate gains with ablation studies to verify each added feature justifies complexity. A limitation is rising maintenance overhead as features grow. Standardize feature extraction into a single module with versioning so deployment artifacts match training exactly. This prevents silent drift when parsers update in production systems or library behavior changes over time.</p><p>Operationalize safely with monitoring that reflects user impact. Track daily alert counts, false positive appeals, time-to-triage, and score calibration drift. Automate backtesting weekly with fresh samples and compare to baseline thresholds. When drift appears, prefer recalibration or threshold tweaks before retraining unless features have clearly degraded. Plan rollouts with staged exposure, such as shadow mode then monitor-only, before enforcement. Document a rollback plan to previous model versions. If you later want to expand beyond URLs, align with a broader playbook on <a href="https://pulsegeek.com/articles/phishing-defense-with-nlp-a-complete-build-guide">multi-signal phishing defenses</a> to integrate content and attachment analysis without destabilizing current workflows.</p><div class="pg-section-summary" data-for="#troubleshoot-and-optimize" role="note" aria-label="Section summary"><h3 class="summary-title">Section highlights</h3><ul class="mini"><li>Mitigate false positives with bounded exceptions and feature adjustments.</li><li>Enrich signals for evasions and validate gains with ablations.</li><li>Monitor impact metrics and prefer recalibration before retraining.</li></ul></div><section class="pg-summary-block pg-quick-start" aria-label="Quick start checklist"><h2>Quick start checklist</h2><ol><li><strong>Define scope:</strong> decide environment, threat behaviors, and target precision-recall bands.</li><li><strong>Collect data:</strong> combine phishing feeds with benign traffic and group by domain.</li><li><strong>Normalize URLs:</strong> lowercase hosts, decode punycode, and safe percent-decode paths.</li><li><strong>Build baseline:</strong> train TF-IDF plus logistic regression with calibration.</li><li><strong>Validate properly:</strong> use grouped folds and a final time-sliced test set.</li><li><strong>Select threshold:</strong> pick operating points from precision-recall tradeoffs.</li><li><strong>Monitor drift:</strong> track alert volume, appeals, and recalibrate when scores shift.</li></ol></section><section id="article-glossary" class="article-glossary" aria-labelledby="article-glossary-heading"><h2 id="article-glossary-heading">Key terms</h2><ul class="article-glossary-list"><li><a href="https://pulsegeek.com/glossary/artificial-intelligence/">Artificial Intelligence</a><span class="def"> — Artificial intelligence is the field of building computer systems that can perform tasks that usually require human thinking, such as understanding language, recognizing patterns, and making decisions.</span></li><li><a href="https://pulsegeek.com/glossary/classification-model/">Classification Model</a><span class="def"> — A model that assigns inputs to discrete categories.</span></li><li><a href="https://pulsegeek.com/glossary/convolutional-neural-network/">Convolutional Neural Network</a><span class="def"> — Neural network using convolutions for pattern learning.</span></li><li><a href="https://pulsegeek.com/glossary/f1-score/">F1 Score</a><span class="def"> — A single measure combining precision and recall.</span></li><li><a href="https://pulsegeek.com/glossary/natural-language-processing/">Natural Language Processing</a><span class="def"> — Natural language processing enables computers to understand, generate, and analyze human language, supporting chatbots, search, summarization, and document processing in business workflows.</span></li><li><a href="https://pulsegeek.com/glossary/training-data/">Training Data</a><span class="def"> — Training data is the labeled or structured information used to teach AI models. Its quality and coverage strongly influence accuracy, fairness, and reliability.</span></li></ul></section><section id="faqs" class="pg-faq" aria-labelledby="faqs-heading"><h2 id="faqs-heading">Frequently asked questions</h2><div class="faq-item"><h3>How do I prevent domain leakage from inflating results?</h3><p>Group samples by registrable domain or eTLD+1 during splitting so all URLs from the same family stay in the same fold. This prevents memorization of hosts from creating misleading performance numbers.</p></div><div class="faq-item"><h3>Which features help with homoglyph and unicode tricks?</h3><p>Decode punycode to Unicode, compute host entropy, and include character n-grams so confusable substitutions are still captured. Optionally flag mixed scripts and unusually high digit ratios in the hostname.</p></div><div class="faq-item"><h3>Why use calibration if the classifier already outputs probabilities?</h3><p>Many models produce scores that are not well calibrated. Using Platt scaling or isotonic regression aligns scores with true likelihoods, enabling consistent thresholds and tiered actions across batches.</p></div><div class="faq-item"><h3>What is a safe initial threshold for blocking?</h3><p>Avoid a universal number. Plot precision and recall on validation data and choose a point that maintains acceptable analyst workload. Start with warnings at a higher threshold and move to blocking after monitoring.</p></div><div class="faq-item"><h3>When should I consider a deep model for URLs?</h3><p>Adopt a deep model when lexical baselines plateau and you can afford inference cost. Keep it scoped to difficult patterns and validate with time-sliced tests to ensure real gains rather than overfitting.</p></div></section><script type="application/ld+json">{ "@context": "https://schema.org", "@type": "FAQPage", "mainEntity": [ { "@type": "Question", "name": "How do I prevent domain leakage from inflating results?", "acceptedAnswer": { "@type": "Answer", "text": "Group samples by registrable domain or eTLD+1 during splitting so all URLs from the same family stay in the same fold. This prevents memorization of hosts from creating misleading performance numbers." } }, { "@type": "Question", "name": "Which features help with homoglyph and unicode tricks?", "acceptedAnswer": { "@type": "Answer", "text": "Decode punycode to Unicode, compute host entropy, and include character n-grams so confusable substitutions are still captured. Optionally flag mixed scripts and unusually high digit ratios in the hostname." } }, { "@type": "Question", "name": "Why use calibration if the classifier already outputs probabilities?", "acceptedAnswer": { "@type": "Answer", "text": "Many models produce scores that are not well calibrated. Using Platt scaling or isotonic regression aligns scores with true likelihoods, enabling consistent thresholds and tiered actions across batches." } }, { "@type": "Question", "name": "What is a safe initial threshold for blocking?", "acceptedAnswer": { "@type": "Answer", "text": "Avoid a universal number. Plot precision and recall on validation data and choose a point that maintains acceptable analyst workload. Start with warnings at a higher threshold and move to blocking after monitoring." } }, { "@type": "Question", "name": "When should I consider a deep model for URLs?", "acceptedAnswer": { "@type": "Answer", "text": "Adopt a deep model when lexical baselines plateau and you can afford inference cost. Keep it scoped to difficult patterns and validate with time-sliced tests to ensure real gains rather than overfitting." } } ] }</script><h2 id="looking-ahead" data-topic="Outlook" data-summary="Plan integrations and next steps">Looking ahead</h2><p>Treat your phishing URL classifier as one component in a layered defense that benefits from enrichment and feedback. Integrate decisions with content analysis, attachment scanning, and user-report loops so ambiguous cases gather more evidence before enforcement. As adoption grows, schedule regular reviews that compare alerting to <a class="glossary-term" href="https://pulsegeek.com/glossary/training-data/" data-tooltip="Training data is the labeled or structured information used to teach AI models. Its quality and coverage strongly influence accuracy, fairness, and reliability." tabindex="0">ground truth</a> refreshed from recent incidents. A practical next step is to align your URL signals with a wider investigation workflow by studying a concise guide to <a href="https://pulsegeek.com/articles/ai-in-cybersecurity-models-pipelines-and-defense">AI detection pipelines and defense use cases</a>, then plan staged integrations. With measured improvements and disciplined validation, your model will remain durable as lures evolve.</p><div class="pg-section-summary" data-for="#looking-ahead" role="note" aria-label="Section summary"><h3 class="summary-title">Section highlights</h3><ul class="mini"><li>Integrate URL verdicts with broader signals for stronger decisions.</li><li>Schedule regular reviews and staged rollouts to manage risk.</li><li>Plan integrations using a clear map of AI defense workflows.</li></ul></div></article><aside class="related-articles" aria-label="Related articles"><h2>Related Articles</h2><ul><li><article class="related-card"><h3><a href="https://pulsegeek.com/articles/ai-data-science-for-phishing-detection-step-by-step">AI Data Science for Phishing Detection: Step by Step</a></h3><p>Learn how to plan, build, validate, and improve an AI data science workflow for phishing detection with clear steps, metrics, and safeguards.</p></article></li><li><article class="related-card"><h3><a href="https://pulsegeek.com/articles/developing-phishing-classifiers-with-ai-best-practices">Developing Phishing Classifiers with AI: Best Practices</a></h3><p>Learn how to plan, build, validate, and optimize AI phishing classifiers with clear steps, evaluation methods, defenses against evasion, and reproducible tooling.</p></article></li><li><article class="related-card"><h3><a href="https://pulsegeek.com/articles/ai-applications-in-email-security-patterns-that-work">AI Applications in Email Security: Patterns That Work</a></h3><p>Explore proven AI applications in email security. Learn patterns for headers, URLs, content, attachments, graphs, reinforcement signals, and ensembles, with tradeoffs and real-world implementation tips.</p></article></li><li><article class="related-card"><h3><a href="https://pulsegeek.com/articles/email-phishing-detection-with-ml-practical-steps">Email Phishing Detection with ML: Practical Steps</a></h3><p>Follow a clear path to build email phishing detection with machine learning. Plan data, engineer features, train, validate, and troubleshoot for reliable results.</p></article></li><li><article class="related-card"><h3><a href="https://pulsegeek.com/articles/detecting-malicious-attachments-with-deep-learning">Detecting Malicious Attachments with Deep Learning</a></h3><p>Learn how deep learning analyzes email attachments safely, from byte-level models to evaluation benchmarks, with tradeoffs for speed, accuracy, and deployment.</p></article></li></ul></aside></main><footer class="container" itemscope itemtype="https://schema.org/Organization"><hr /><nav aria-label="Footer navigation" itemscope itemtype="https://schema.org/SiteNavigationElement"><ul style="list-style:none; padding-left:0; margin:0; display:flex; flex-wrap:wrap; gap:.65rem;"><li itemprop="name"><a href="https://pulsegeek.com/about/" itemprop="url">About</a></li><li itemprop="name"><a href="https://pulsegeek.com/contact/" itemprop="url">Contact</a></li><li itemprop="name"><a href="https://pulsegeek.com/privacy/" itemprop="url">Privacy&nbsp;Policy</a></li><li itemprop="name"><a href="https://pulsegeek.com/terms/" itemprop="url">Terms&nbsp;of&nbsp;Service</a></li><li itemprop="name"><a href="https://pulsegeek.com/site-map/" itemprop="url">HTML&nbsp;Sitemap</a></li><li itemprop="name"><a href="https://pulsegeek.com/rss.xml" itemprop="url" title="RSS 2.0 feed">RSS&nbsp;Feed</a></li><li itemprop="name"><a href="https://pulsegeek.com/atom.xml" itemprop="url" title="Atom 1.0 feed">Atom</a></li><li itemprop="name"><a href="https://pulsegeek.com/feed.json" itemprop="url" title="JSON Feed 1.1">JSON&nbsp;Feed</a></li></ul></nav><small style="display:block; margin-top:.75rem;"> © 2025 <span itemprop="name">PulseGeek</span>. All rights reserved. </small></footer><script type="module">
for (const code of document.querySelectorAll('figure.code-example pre code')) {
  if (code.dataset.lnDone) continue;
  const raw = code.innerHTML.replace(/\r/g,'');
  let lines = raw.split('\n');
  if (lines.length && lines[lines.length-1] === '') lines.pop();
  if (lines.length < 2) continue;
  code.innerHTML = lines.map(l => `<span>${l || '&#8203;'}</span>`).join('\n');
  code.dataset.lnDone = '1';
  code.closest('figure.code-example')?.classList.add('line-numbers');
}
</script></body></html> 